{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72723f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers<3.0,>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.43.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.2)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-12.0.0-py2.py3-none-win_amd64.whl (13.1 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-win_amd64.whl (2.8 MB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.1-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting gast<0.5.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.8,~=2.7.0rc0\n",
      "  Downloading tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.0.1-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting keras<2.8,>=2.7.0rc0\n",
      "  Downloading keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.13.3-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.21.0\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.2-py3-none-any.whl (288 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\melys\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=2fe5bfc4d72d46330b4bf5507bec980906ba954872f539c08ab8f67e18a258b4\n",
      "  Stored in directory: c:\\users\\melys\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-4.2.4 flatbuffers-2.0 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.43.0 h5py-3.6.0 keras-2.7.0 keras-preprocessing-1.1.2 libclang-12.0.0 markdown-3.3.6 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0 tensorflow-io-gcs-filesystem-0.23.1 termcolor-1.1.0 typing-extensions-4.0.1 werkzeug-2.0.2 wrapt-1.13.3\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0acc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.7.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225b4b5",
   "metadata": {},
   "source": [
    "## Chargement des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ab57d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir les exemples de données d'entiers en nombres à virgule flottante\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de8d95b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef388ed8",
   "metadata": {},
   "source": [
    "Il y a 60 000 images dans l'ensemble d'apprentissage, chaque image étant représentée en 28 x 28 pixels.  \n",
    "Chaque étiquette est un entier compris entre 0 et 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb29f682",
   "metadata": {},
   "source": [
    "## Construction du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfba604",
   "metadata": {},
   "source": [
    "Modèle par empilement de couches: Sequentialmodel est approprié pour une pile simple de couches où chaque couche a exactement un tenseur d'entrée et un tenseur de sortie(pas tres flexible).  \n",
    "Layers : liste de couches à ajouter au modèle comme CONV2D et LSTM.\n",
    "\n",
    "Les couches : \n",
    "\n",
    "* flatten (applatir) réduit simplement les vecteurs tenseurs, transforme le format à partir d' un tableau à deux dimensions (batch,) à un réseau à une dimension ([batch,1]).L'aplatissement ajoute une dimension de canal supplémentaire. Cette couche n'a pas de paramètres à apprendre ; elle reformate seulement les données.\n",
    "\n",
    "* dropout couche dabondon : définit de manière aléatoire les unités d'entrée sur 0 avec une fréquence de rate à chaque étape pendant le temps d'entraînement -> ce qui permet d'éviter le surapprentissage. Les entrées non définies sur 0 sont augmentées de $ \\frac{1}{1 - taux} $ de sorte que la somme de toutes les entrées reste inchangée.\n",
    "\n",
    "* couche dense : est une couche neuronale densément connectée ou entièrement connectée, ou chaque neurone est connecté à tous les neurones de la couche précédente, elle consiste essentiellement en des poids (w) que nous multiplions par l'entrée, nous ajoutons des biais (b) et appliquons une fonction d'activation .\n",
    "\n",
    "Fonctions d'activation: \n",
    "* ReLU : réseau très profond ou la charge de calcul est un problème, $ f(x)=max(0,x) $.\n",
    "* Softmax : plus d'une seule sortie (classification à plus de 2 classes).Softmax convertit un vecteur de valeurs en une distribution de probabilité.  Les éléments du vecteur de sortie sont dans la plage (0, 1) et la somme à 1.  Chaque vecteur est géré indépendamment. L' axisargument définit sur quel axe de l'entrée la fonction est appliquée.    Softmax est souvent utilisé comme activation pour la dernière couche d'un réseau de classification car le résultat pourrait être interprété comme une distribution de probabilité.  le softmax de chaque vecteur x est calculé comme $ f(x)_i = \\frac{\\exp^{x_i}}{\\sum_{k=0}^K \\exp^{x_k}}$   C'est-à-dire que la composante i du vecteur $ f(x) $ est égale à l'exponentielle de la composante i du vecteur x divisée par la somme des exponentielles de toutes les composantes de x. \n",
    "\n",
    "* Sigmoid : une seule sortie entre 0 et 1 (classification binaire ), $ f(x) = \\frac{\\exp^{x}}{\\exp^{x} + 1}$ \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43f4d759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d207c771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38991493, -0.10446891, -0.27904359, -0.0647276 ,  1.0073326 ,\n",
       "        -0.36468804, -0.43663678, -0.05834304, -0.31406555, -0.7141819 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#modèle retourne un vecteur de logits ou log-odds scores, un pour chaque classe.\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0d31e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.14319237, 0.08733969, 0.07334912, 0.0908806 , 0.2654978 ,\n",
       "        0.06732866, 0.06265461, 0.09146267, 0.07082474, 0.04746972]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vecteur de probabilité\n",
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f78fc",
   "metadata": {},
   "source": [
    "## Compilation du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae39f3b",
   "metadata": {},
   "source": [
    "* Définir une fonction de perte : mesure qui évalue la précision ici on calcule la perte d'entropie croisée entre les étiquettes et les prédictions, qui prend un vecteur de logits et un True index et retourne une perte scalaire pour chaque exemple.  \n",
    "Cette perte est égale au log de probabilité négatif de la vraie classe.   \n",
    "La perte est nulle si le modèle est sûr de la bonne classe.\n",
    "\n",
    "* Optimiseur adam : comment le modèle est mis à jour en fonction des données qu'il voit et sa fonction de perte, \"adam\" un algo de descente de gradient stochastique  \n",
    "« efficace du point de vue informatique, nécessite peu de mémoire, est invariante au redimensionnement diagonal des gradients \n",
    "et convient bien aux problèmes volumineux en termes de données/paramètres ».  \n",
    "* Liste des métriques à évaluer par le modèle lors de l'entraînement et des tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39eb1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a96072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6981692"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a13fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation du modèle\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db3251",
   "metadata": {},
   "source": [
    "## Entrainement du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f48a4",
   "metadata": {},
   "source": [
    "Entraîner le modèle pour un nombre fixe d'époques (itérations sur un jeu de données) qui est une méthode pour ajuster vos paramètres du modèle et de minimiser la perte.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d05ef98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2970 - accuracy: 0.9153\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1457 - accuracy: 0.9560\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.1082 - accuracy: 0.9678\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.0885 - accuracy: 0.9723\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0772 - accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1abcb5c14f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c995abbb",
   "metadata": {},
   "source": [
    "## Evaluation du modèle:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d96d3f",
   "metadata": {},
   "source": [
    "La méthode d'évaluation  vérifie les performances du modèles, généralement sur une « validation-set » ou « Test-set », et renvoie la valeur de perte et les valeurs des métriques pour le modèle en mode test.  \n",
    "Les types de modes(verbose):\n",
    "* verbose = 1, qui comprend à la fois une barre de progression et une ligne par époque (le mode par defaut).\n",
    "* verbose = 0, signifie silencieux.\n",
    "* verbose = 2, une ligne par époque, c'est-à-dire n° d'époque/n° total des époques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "748dc09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0763 - accuracy: 0.9771 - 536ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07625770568847656, 0.9771000146865845]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25a0bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Si vous souhaitez que votre modèle renvoie une probabilité, \n",
    "#vous pouvez envelopper le modèle entraîné et lui attacher le softmax \n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfd7ff3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[1.3172706e-07, 3.6173655e-09, 1.8448275e-06, 1.9058818e-05,\n",
       "        2.1683927e-11, 8.7314561e-08, 3.3553360e-14, 9.9997449e-01,\n",
       "        2.1785443e-08, 4.2398287e-06],\n",
       "       [1.5309016e-08, 4.3805183e-05, 9.9990988e-01, 4.2988402e-05,\n",
       "        1.3971094e-15, 1.4713569e-06, 1.8938621e-07, 2.4458601e-12,\n",
       "        1.6908215e-06, 8.4900836e-14],\n",
       "       [6.3323973e-06, 9.9708956e-01, 3.8307739e-04, 2.9523535e-05,\n",
       "        8.5803622e-05, 5.0562234e-05, 5.3963635e-05, 1.0310108e-03,\n",
       "        1.2698689e-03, 4.2644555e-07],\n",
       "       [9.9995708e-01, 6.9490175e-10, 1.0611793e-05, 3.3243057e-07,\n",
       "        5.2590809e-07, 8.4436615e-06, 1.0045597e-05, 7.0877313e-06,\n",
       "        8.8360117e-08, 5.8305091e-06],\n",
       "       [3.0610022e-06, 1.0824927e-09, 1.2345213e-06, 5.8230320e-08,\n",
       "        9.9159509e-01, 1.6952828e-06, 6.7381848e-06, 3.0216164e-05,\n",
       "        2.1402686e-06, 8.3598122e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff8785d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
